"""
Integraci√≥n de m√©tricas RAGAS para evaluaci√≥n est√°ndar.
"""
import logging
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

def calculate_ragas_metrics(user_query, model_responses, contexts, judge_response, config=None):
    """
    Calcula m√©tricas RAGAS usando el MISMO modelo juez seleccionado por el usuario
    RAGAS 0.2.0 compatible
    """
    try:
        # ‚úÖ USAR EL MISMO PATR√ìN QUE LAS M√âTRICAS NATIVAS
        judge_model_name = config.get("judge_model") if config else None
        llm_url = config.get("llm_url") if config else "http://localhost:11434"
        
        if not judge_model_name:
            print("‚ùå No se proporcion√≥ modelo juez para RAGAS")
            return {}
        
        print(f"üéØ RAGAS usando modelo juez seleccionado: {judge_model_name}")
        
        # ‚úÖ IMPORTS CORRECTOS PARA RAGAS 0.2.0
        try:
            # Intentar diferentes rutas de import para RAGAS 0.2.0
            from ragas.llms.llamaindex import LlamaIndexLLM
            from ragas.embeddings.llamaindex import LlamaIndexEmbeddings
            print("‚úÖ Imports directos funcionando")
        except ImportError:
            try:
                # Alternativa para RAGAS 0.2.0
                from ragas.llms import llamaindex_llm
                from ragas.embeddings import llamaindex_embeddings
                LlamaIndexLLM = llamaindex_llm.LlamaIndexLLM
                LlamaIndexEmbeddings = llamaindex_embeddings.LlamaIndexEmbeddings
                print("‚úÖ Imports alternativos funcionando")
            except ImportError:
                # Si nada funciona, usar LangChain directamente
                print("‚ö†Ô∏è LlamaIndex wrappers no disponibles, usando LangChain")
                return calculate_ragas_with_langchain(user_query, model_responses, contexts, judge_response, config)
        
        # ‚úÖ CREAR EL MISMO LLM QUE USAN LAS M√âTRICAS NATIVAS
        from llama_index.llms.ollama import Ollama
        judge_llm = Ollama(model=judge_model_name, base_url=llm_url, request_timeout=300.0)
        
        # ‚úÖ CONFIGURAR RAGAS CON ESE LLM
        from ragas import evaluate
        from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall
        
        ragas_llm = LlamaIndexLLM(llm=judge_llm)
        
        # ‚úÖ USAR EL MISMO EMBED_MODEL QUE EL PROYECTO
        from cache_manager import get_cache_manager
        cache_manager = get_cache_manager()
        embed_model = cache_manager.get_cached_embedding_model()
        ragas_embeddings = LlamaIndexEmbeddings(embeddings=embed_model)
        
        # Configurar m√©tricas RAGAS
        faithfulness.llm = ragas_llm
        answer_relevancy.llm = ragas_llm
        answer_relevancy.embeddings = ragas_embeddings
        context_precision.llm = ragas_llm
        context_recall.llm = ragas_llm
        context_recall.embeddings = ragas_embeddings
        
        print(f"‚úÖ RAGAS configurado con juez: {judge_model_name}")
        
        # Calcular m√©tricas
        ragas_results = {}
        
        for model_name, response_text in model_responses.items():
            try:
                from datasets import Dataset
                
                data = {
                    "question": [user_query],
                    "answer": [response_text],
                    "contexts": [contexts if contexts else ["No context available"]],
                    "ground_truth": [judge_response]
                }
                
                dataset = Dataset.from_dict(data)
                
                result = evaluate(
                    dataset=dataset,
                    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]
                )
                
                ragas_results[model_name] = {
                    "ragas_faithfulness": float(result["faithfulness"]),
                    "ragas_answer_relevancy": float(result["answer_relevancy"]),
                    "ragas_context_precision": float(result["context_precision"]),
                    "ragas_context_recall": float(result["context_recall"])
                }
                
                print(f"‚úÖ RAGAS calculado para {model_name}")
                
            except Exception as e:
                print(f"‚ùå Error calculating RAGAS metrics for {model_name}: {e}")
                ragas_results[model_name] = {"ragas_error": str(e)}
        
        return ragas_results
        
    except Exception as e:
        print(f"‚ùå Error general en RAGAS: {e}")
        import traceback
        traceback.print_exc()
        return {}

def calculate_ragas_with_langchain(user_query, model_responses, contexts, judge_response, config):
    """
    Fallback usando LangChain directamente para RAGAS 0.2.0
    """
    try:
        print("üîÑ Usando fallback con LangChain para RAGAS...")
        
        # Usar LangChain Ollama directamente
        from langchain_community.llms import Ollama as LangChainOllama
        from ragas import evaluate
        from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall
        
        judge_model_name = config.get("judge_model")
        llm_url = config.get("llm_url", "http://localhost:11434")
        
        # Configurar LangChain LLM
        langchain_llm = LangChainOllama(
            model=judge_model_name,
            base_url=llm_url,
            timeout=300
        )
        
        # Configurar m√©tricas RAGAS con LangChain LLM
        faithfulness.llm = langchain_llm
        answer_relevancy.llm = langchain_llm
        context_precision.llm = langchain_llm
        context_recall.llm = langchain_llm
        
        print(f"‚úÖ RAGAS configurado con LangChain: {judge_model_name}")
        
        # Resto igual...
        ragas_results = {}
        
        for model_name, response_text in model_responses.items():
            try:
                from datasets import Dataset
                
                data = {
                    "question": [user_query],
                    "answer": [response_text],
                    "contexts": [contexts if contexts else ["No context available"]],
                    "ground_truth": [judge_response]
                }
                
                dataset = Dataset.from_dict(data)
                
                result = evaluate(
                    dataset=dataset,
                    metrics=[faithfulness, answer_relevancy, context_precision, context_recall]
                )
                
                ragas_results[model_name] = {
                    "ragas_faithfulness": float(result["faithfulness"]),
                    "ragas_answer_relevancy": float(result["answer_relevancy"]),
                    "ragas_context_precision": float(result["context_precision"]),
                    "ragas_context_recall": float(result["context_recall"])
                }
                
                print(f"‚úÖ RAGAS calculado para {model_name}")
                
            except Exception as e:
                print(f"‚ùå Error calculating RAGAS metrics for {model_name}: {e}")
                ragas_results[model_name] = {"ragas_error": str(e)}
        
        return ragas_results
        
    except Exception as e:
        print(f"‚ùå Error en fallback LangChain: {e}")
        return {}

def validate_ragas_inputs(user_query: str, contexts: List[str], answer: str) -> bool:
    """
    Valida que los inputs para RAGAS sean v√°lidos.
    """
    if not user_query or not user_query.strip():
        return False
    if not answer or not answer.strip():
        return False
    if not contexts or len(contexts) == 0:
        return False
    return True